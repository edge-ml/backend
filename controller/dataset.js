const Model = require("../models/dataset").model;
const UserModel = require("../models/user").model;
const Experiment = require("../models/experiment").model;
const DatasetLabeling = require("../models/datasetLabeling").model;
const DatasetLabel = require("../models/datasetLabel").model;
const ProjectModel = require("../models/project").model;
const DeviceApi = require("../models/deviceApi").model;
const TimeSeries = require("../models/timeSeries").model;
// const TimeSeriesBucket = require("../models/timeSeries").bucket;
const FSModel = require('../models/timeSeries').FSModel;
const Readable = require('stream').Readable;
const gridFS = require('mongoose-gridfs');
const { pipeline } = require('stream/promises');

const mongoose = require("mongoose");

// let TimeSeriesModel;
let bucket;

mongoose.connection.once('open', () => {
  // bucket = gridFS.createBucket({bucketName: 'TimeSeries'})
  console.log('creating');
  // TimeSeriesModel = gridFS.createModel({ modelName: 'TimeSeries' });
  bucket = gridFS.createBucket();
})


/**
 * Util Function
 * Create labelings from experiment
 */
async function autoCreateLabelings(dataset) {
  const experiment = await Experiment.findById(dataset.experiments);
  const datasetLabeling = new DatasetLabeling({
    labelingId: experiment,
    labels: [],
  });
  let { start } = dataset;
  let end;
  for (let i = 0; i < experiment.instructions.length; i++) {
    end = start + experiment.instructions[i].duration;
    const datasetLabel = new DatasetLabel({
      name: `autogenerated datasetLabel ${i}`,
      type: experiment.instructions[i].labelType,
      start,
      end,
    });
    start = end;
    await datasetLabel.save();
    datasetLabeling.labels.push(datasetLabel);
    i++;
  }
  await datasetLabeling.save();
  return datasetLabeling;
}

/**
 * get all datasets
 */
async function getDatasets(ctx) {
  const projectId = ctx.header.project;
  const project = await ProjectModel.findOne({ _id: projectId });
  const datasets = await Model.find({ _id: project.datasets });
  ctx.body = datasets;
  ctx.status = 200;
}

function streamToJSON (stream) {
  const chunks = [];
  return new Promise((resolve, reject) => {
    stream.on('data', (chunk) => chunks.push(Buffer.from(chunk)));
    stream.on('error', (err) => reject(err));
    stream.on('end', () => resolve(JSON.parse(Buffer.concat(chunks).toString())));
  })
}

async function populateTimeSeries(dataset) {
  const timeseriesPopulation = [];
  const newDataset = []
  for (const [i, ds] of dataset.entries()) {
    timeseriesPopulation.push([]);
    for (const ts of ds.timeSeries) {
      const readStream = bucket.readFile({ _id: ts });
      const data = await streamToJSON(readStream);
      timeseriesPopulation[i].push(data);
    }
  }
  for (let i = 0; i < dataset.length; i++) {
    const newDs = JSON.parse(JSON.stringify(dataset[i]));
    newDs.timeSeries = timeseriesPopulation[i]
    newDataset.push(newDs)
  }
  console.log('updated')
  console.log(newDataset)
  return newDataset;
}

/**
 * get dataset by id
 */
async function getDatasetById(ctx) {
  const project = await ProjectModel.findOne({ _id: ctx.header.project });
  var dataset = undefined;
  if (ctx.request.query.onlyMetaData) {
    dataset = await Model.find({
      $and: [{ _id: ctx.params.id }, { _id: project.datasets }],
    });
  } else {
    console.log('jo')
    dataset = await Model.find({
      $and: [{ _id: ctx.params.id }, { _id: project.datasets }],
    }).exec();
  }

  // populate timeseries manually using gridfs
  
  dataset = await populateTimeSeries(dataset);

  console.log('printing dataset')
  console.log(dataset)
  if (dataset.length === 1) {
    ctx.body = dataset[0];
    ctx.status = 200;
  } else {
    ctx.body = { error: "Dataset not in requested project" };
    ctx.status = 400;
  }
  return ctx.body;
}

/**
 * get dataset lock by id
 */
async function getDatasetLockById(ctx) {
  const project = await ProjectModel.findOne({ _id: ctx.header.project });
  const lock = await Model.find({
    $and: [{ _id: ctx.params.id }, { _id: project.datasets }],
  })
    .select("canEdit")
    .exec();
  if (lock.length === 1) {
    ctx.body = { canEdit: lock[0].canEdit };
    ctx.status = 200;
  } else {
    ctx.body = { error: "Dataset not in requested project" };
    ctx.status = 400;
  }
  return ctx.body;
}

/**
 * create a new dataset
 */
async function createDataset(ctx) {
  const dataset = ctx.request.body;
  dataset.projectId = ctx.header.project;
  // if userId empty, set it to requesting user
  if (!dataset.userId) {
    const { authId } = ctx.state;
    const user = await UserModel.findOne({ authId });
    dataset.userId = user._id;
  }

  if (
    "experiments" in dataset &&
    dataset.experiments !== null &&
    !("labelings" in dataset)
  ) {
    dataset.labelings = await autoCreateLabelings(dataset);
  } else if (
    "experiments" in dataset &&
    dataset.experiments !== null &&
    "labelings" in dataset &&
    dataset.labelings.length > 0
  ) {
    ctx.body = { error: "Do not set experiment and labelings" };
    ctx.status = 400;
    return ctx;
  }

  const document = new Model({ ...dataset, timeSeries: undefined });
  await document.save();

  console.log(Buffer.byteLength(JSON.stringify(dataset.timeSeries)));

  for (var i = 0; i < dataset.timeSeries.length; i++) {
    const _id = new mongoose.Types.ObjectId();
    const readable = new Readable();
    console.log('before upload')
    dataset.timeSeries[i].offset = 0;
    console.log(Object.keys(dataset.timeSeries[i]))
    const buf = Buffer.from(JSON.stringify(dataset.timeSeries[i]));
    readable.push(buf);
    readable.push(null);
    const filename = 'ts' + _id;
    console.log('here')
    bucket.writeFile({ filename, _id }, readable, (error, file) => {
      console.log(file);
    });
    // TimeSeriesBucket.writeFile({ filename }, readStream, (error, file) => { console.log('done') });
    // const writeStream = TimeSeriesBucket.writeFile({ filename }, readStream);
    document.timeSeries.push(_id);
  }

  await document.save();

  await ProjectModel.findByIdAndUpdate(ctx.header.project, {
    $push: { datasets: document._id },
  });

  ctx.body = document;
  ctx.status = 201;
  return ctx;
}

async function updateDatasetById(ctx) {
  try {
    const dataset = ctx.request.body;
    const project = await ProjectModel.findOne({ _id: ctx.header.project });
    var timeSeries = undefined;
    if (project.datasets.includes(ctx.params.id)) {
      if (dataset.timeSeries) {
        timeSeries = await Promise.all(
          dataset.timeSeries.map((elm) => {
            if (elm._id) {
              return TimeSeries.findByIdAndUpdate(elm._id, elm);
            } else {
              elm.dataset = ctx.params.id;
              return TimeSeries.create(elm);
            }
          })
        );
        dataset.timeSeries = timeSeries.map((elm) => elm._id);
      }
      await Model.findByIdAndUpdate(ctx.params.id, dataset);
      ctx.body = { message: `updated dataset with id: ${ctx.params.id}` };
      ctx.status = 200;
    } else {
      ctx.body = { error: "Forbidden" };
      ctx.status = 403;
    }
    return ctx;
  } catch (e) {
    console.log(e);
  }
}

async function canEditDatasetById(ctx) { // we could use the update method above, but it sends the whole dataset, which is unnecessarily SLOW
  try {
    const { canEdit } = ctx.request.body;
    const project = await ProjectModel.findOne({ _id: ctx.header.project });
    if (project.datasets.includes(ctx.params.id)) {
      await Model.findByIdAndUpdate(ctx.params.id, {
        $set: { canEdit: canEdit }
      });
      ctx.body = { message: `changed canEdit for dataset with id: ${ctx.params.id}` };
      ctx.status = 200;
    } else {
      ctx.body = { error: "Forbidden" };
      ctx.status = 403;
    }
    return ctx;
  } catch (e) {
    console.log(e);
  }
}

/**
 * delete a dataset specified by id
 */
async function deleteDatasetById(ctx) {
  const project = await ProjectModel.findOne({ _id: ctx.header.project });
  const dataset = await Model.findOneAndDelete({
    $and: [{ _id: ctx.params.id }, { _id: project.datasets }],
  });
  if (dataset !== null) {
    await ProjectModel.updateOne(
      { _id: ctx.header.project },
      { $pull: { datasets: ctx.params.id } }
    );

    await TimeSeries.deleteMany({ _id: { $in: dataset.timeSeries } });

    await DeviceApi.updateMany(
      { projectId: project._id },
      { $pull: { datasets: { dataset: ctx.params.id } } }
    );

    ctx.body = { message: `deleted dataset with id: ${ctx.params.id}` };
    ctx.status = 200;
  } else {
    ctx.body = { error: "Dataset not found" };
    ctx.status = 400;
  }
  return ctx;
}

module.exports = {
  getDatasets,
  getDatasetById,
  getDatasetLockById,
  createDataset,
  updateDatasetById,
  canEditDatasetById,
  deleteDatasetById,
};
